# -*- coding: utf-8 -*-
"""eee431project.pynb adlı not defterinin kopyası

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w5f0V5EKxRQUz3yRMKVOPeJGrpqPrihG
"""

# Gerekli kütüphaneleri yükleme
!pip install librosa matplotlib scipy transformers

from google.colab import drive
drive.mount('/content/drive')

!ls /content/

!mkdir -p /content/LibriSpeech
!tar -xvf /content/dev-clean.tar -C /content/LibriSpeech/

!ls /content/LibriSpeech/

!ls -R /content/LibriSpeech/

!ls "/content/LibriSpeech/dev-clean/"

!ls -R /content/LibriSpeech/

!ls /content/LibriSpeech/

!tar -xvf /content/dev-clean.tar -C /content/LibriSpeech/

!ls /content/LibriSpeech/

!find /content/LibriSpeech/

!pip install librosa soundfile

!tar -xvf dosya_adı.tar

from google.colab import drive
drive.mount('/content/drive')

!ls "/content/drive/My Drive/"

file_path = "/content/drive/My Drive/undertheguns_01_wittenmyer_64kb.wav"

import librosa

# Dosyayı yüklenmesi
audio, sr = librosa.load(file_path, sr=None)

print(f"Sampling Rate: {sr}")
print(f"Audio Length (seconds): {len(audio)/sr}")

import matplotlib.pyplot as plt

# Ses dalgasını görselleştirme
plt.figure(figsize=(12, 4))
plt.plot(audio)
plt.title("Waveform")
plt.xlabel("Samples")
plt.ylabel("Amplitude")
plt.show()

import numpy as np
import librosa.display

# Short-Time Fourier Transform (STFT)
stft = librosa.stft(audio)
spectrogram = librosa.amplitude_to_db(np.abs(stft))

# Spektrogramı görselleştir
plt.figure(figsize=(12, 6))
librosa.display.specshow(spectrogram, sr=sr, x_axis='time', y_axis='hz', cmap='magma')
plt.colorbar(format="%+2.0f dB")
plt.title("Spectrogram")
plt.xlabel("Time (s)")
plt.ylabel("Frequency (Hz)")
plt.show()

"""**1. Google Drive Bağlantısı ve LibriSpeech Veri Seti Yükleme:**

İlk olarak, Google Drive'ı bağladık ve oradan LibriSpeech veri setini yükledik. Bu, sesli dil tanıma (ASR) için yaygın olarak kullanılan büyük bir veri seti. Bu veri setinde bulunan ses dosyalarını kullanarak ses verisi üzerinde çalışacağız.
"""

from google.colab import drive
drive.mount('/content/drive')

!ls "/content/drive/MyDrive/LibriSpeech/"

"""**2. Ses Dosyalarını Çıkartma:**

LibriSpeech veri seti .tar formatında bir arşiv dosyası olduğu için, önce bu dosyayı çıkartmamız gerekiyordu. tar komutu ile bu dosyayı açtık ve çıkarttık.Bu komutla veriyi çıkartıp, ses dosyalarına erişim sağladık.
"""

!mkdir -p /content/LibriSpeech
!tar -xvf "/content/drive/MyDrive/LibriSpeech/dev-clean.tar" -C "/content/LibriSpeech/"

!ls "/content/LibriSpeech/"

!ls "/content/LibriSpeech/dev-clean/3853/163249/"

!find /content/LibriSpeech/ -name "*.flac"

"""**3. Ses Dosyasını Yükleme ve İnceleme:**

Örnek olarak bir ses dosyasını yükledik. librosa kütüphanesini kullanarak ses dosyasını okuduk ve temel bilgileri yazdırdık. Bu, sesin örnekleme frekansı ve uzunluğu gibi bilgileri içeriyor.
"""

example_file = "/content/LibriSpeech/LibriSpeech/dev-clean/2902/9006/2902-9006-0014.flac"  # Buraya doğru dosya yolunu koyun

# Librosa ile dosyayı yükle
import librosa
y, sr = librosa.load(example_file, sr=None)

# Ses dosyasının bazı bilgilerini yazdır
print(f"Örnekleme frekansı (Sample Rate): {sr}")
print(f"Ses uzunluğu (saniye): {len(y) / sr}")

"""**4. Mel-Spektrogram ve Görselleştirme:**

Sesin Mel-spektrogramını oluşturarak sesin frekans dağılımını görselleştirdik. Bu, sesin hangi frekanslarda daha güçlü olduğunu gösteriyor. librosa.feature.melspectrogram() fonksiyonu ile Mel-spektrogramını oluşturduk, ardından librosa.power_to_db() ile bunu desibel (dB) birimine dönüştürdük.Burada, Mel-spektrogramı görselleştirerek sesin frekans bileşenlerini ve enerjisini zaman içinde nasıl değiştiğini gözlemledik.
"""

import librosa.display
import matplotlib.pyplot as plt
import numpy as np

# Mel-spektrogram oluştur
S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)

# Mel-spektrogramı dB birimine dönüştür
S_dB = librosa.power_to_db(S, ref=np.max)

# Görselleştirme
plt.figure(figsize=(10, 4))
librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', fmax=8000)
plt.colorbar(format='%+2.0f dB')
plt.title('Mel-Spectrogram')
plt.tight_layout()
plt.show()

"""**5. STFT (Kısa Zamanlı Fourier Dönüşümü):**

STFT kullanarak sesin zaman-frekans analizini yaptık. Bu işlem, sesin belirli zaman dilimlerinde hangi frekansta olduğunu gösteriyor.STFT ile sesin frekans bileşenlerini zaman dilimlerine ayırarak analiz ettik.


"""

# STFT hesapla
D = librosa.stft(y)
S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

# Spektrogram görselleştir
plt.figure(figsize=(10, 4))
librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='log')
plt.colorbar(format='%+2.0f dB')
plt.title('Spectrogram (STFT)')
plt.tight_layout()
plt.show()

"""**6. FFT (Hızlı Fourier Dönüşümü) ile Frekans Analizi:**

FFT ile sesin frekans spektrumunu çıkardık. Bu, sesin hangi frekans bileşenlerinin daha baskın olduğunu gösteriyor.Bu kod, sesin frekans spektrumunu göstererek, hangi frekansların daha güçlü olduğunu ortaya koydu.
"""

import scipy.fft

# FFT (Fast Fourier Transform) ile frekans analizi
fft = scipy.fft.fft(y)
magnitude = np.abs(fft)
frequency = np.linspace(0, sr, len(magnitude))

# Frekans spektrumu
plt.figure(figsize=(10, 4))
plt.plot(frequency[:len(frequency)//2], magnitude[:len(magnitude)//2])
plt.xlabel('Frequency (Hz)')
plt.ylabel('Magnitude')
plt.title('Frequency Spectrum')
plt.grid()
plt.show()

import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt

# Örnek bir ses dosyasını yükle
example_file = "/content/LibriSpeech/LibriSpeech/dev-clean/2902/9006/2902-9006-0014.flac"
y, sr = librosa.load(example_file, sr=16000)

# Mel-spektrogram oluştur
mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)
mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)

# Mel-spektrogram görselleştir
plt.figure(figsize=(10, 4))
librosa.display.specshow(mel_spectrogram_db, sr=sr, x_axis='time', y_axis='mel', fmax=8000)
plt.colorbar(format='%+2.0f dB')
plt.title('Mel-Spectrogram')
plt.tight_layout()
plt.show()

# Mel-spektrogram verisini düzleştir
mel_features = mel_spectrogram_db.flatten()
print("Mel-spektrogram özellik boyutu:", mel_features.shape)

"""**7. Wav2Vec2 ile Özellik Çıkartımı:**

Wav2Vec2, ses verisinden derin özellikler çıkartan bir model. Bu modeli kullanarak sesin bağlamsal özelliklerini çıkarttık.Burada, Wav2Vec2 modelini kullanarak ses verisinden gizli özellikler çıkarttık.


"""

from transformers import Wav2Vec2Processor, Wav2Vec2Model
import torch

# Wav2Vec için işleyici ve model yükleme
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
model = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base-960h")

# Veriyi işleyip modele besle
inputs = processor(y, sampling_rate=sr, return_tensors="pt", padding=True)
with torch.no_grad():
    features = model(**inputs).last_hidden_state

print("Özellik çıkışı boyutu:", features.shape)

"""**8. Özelliklerin Görselleştirilmesi**

Çıkarttığımız özelliklerin neye benzediğini görselleştirerek, modelin ses verisinden çıkardığı spektrogram özelliklerini gözlemledik.Bu adımda, çıkarılan spektrogram özelliklerini görselleştirerek modelin ses üzerinde nasıl çalıştığını anlamaya çalıştık.

"""

# Öznitelikleri görselleştir
plt.figure(figsize=(10, 4))
plt.imshow(features[0].numpy(), aspect='auto', origin='lower')
plt.colorbar()
plt.title("LLM Çıkışı (Spectral Features)")
plt.xlabel("Zaman")
plt.ylabel("Özellik Boyutu")
plt.show()

import numpy as np

# Özellikleri kaydet
np.save("features.npy", features.cpu().numpy())

# Özellikleri yükle
loaded_features = np.load("features.npy")

"""**9. PCA ile Özellik İndirgeme**

PCA (Principal Component Analysis) kullanarak, ses verisindeki yüksek boyutlu verileri indirgedik ve daha anlamlı hale getirdik. Bu adımda, daha düşük boyutlu bir veri kümesi elde ettik.Bu adımda, ses verisinin özelliklerini 2D alana indirgedik ve görselleştirdik.
"""

# Özellikleri 2D hale getirme
flattened_features = features.cpu().numpy().reshape(-1, features.shape[-1])

# PCA ile indirgeme
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

pca = PCA(n_components=2)
reduced_features = pca.fit_transform(flattened_features)

# Görselleştir
plt.figure(figsize=(8, 6))
plt.scatter(reduced_features[:, 0], reduced_features[:, 1], alpha=0.5)
plt.title("PCA ile Özellik Görselleştirme")
plt.xlabel("PCA Bileşen 1")
plt.ylabel("PCA Bileşen 2")
plt.show()

import os

# Ses dosyalarının bulunduğu dizinlerin yollarını içeren liste
audio_paths = [
    "/content/LibriSpeech/dev-clean/3853/163249/3853-163249-0000.flac",
    "/content/LibriSpeech/dev-clean/3853/163249/3853-163249-0001.flac",
    "/content/LibriSpeech/dev-clean/1272/128104/1272-128104-0000.flac",
    # Daha fazla ses dosyası yolu ekleyebilirsiniz...
]

# Etiketleri çıkarma (her ses dosyasının bulunduğu dizinin adı)
labels = [os.path.basename(os.path.dirname(os.path.dirname(path))) for path in audio_paths]

# Etiketlerin sayısını kontrol edelim
print("Labels length:", len(labels))  # Bu uzunluk, ses dosyasının sayısı kadar olmalı
print("Labels (ilk birkaç):", labels[:10])  # İlk birkaç etiketi kontrol etme

print("Features reduced shape:", features_reduced.shape)  # Bu, (1020, 2) şeklinde olmalı
print("Labels length:", len(labels))  # Bu da 1020 olmalı

labels = []  # Etiketler listesi
for path in audio_paths:
    label = os.path.basename(os.path.dirname(path))  # Ses dosyasının bulunduğu dizinin adı etiket olacak
    labels.append(label)

print("Labels length:", len(labels))  # Bu uzunluk 1020 olmalı

# Audio paths'i ve etiketleri kontrol etme
for path in audio_paths:
    print("Audio file path:", path)
    label = os.path.basename(os.path.dirname(path))
    print("Label:", label)
    labels.append(label)

print("Number of audio files:", len(audio_paths))

labels = [os.path.basename(os.path.dirname(path)) for path in audio_paths]
print("Labels length:", len(labels))

# 'LibriSpeech' klasörünü kontrol edelim
libri_directory = '/content/drive/MyDrive/LibriSpeech/'
print("LibriSpeech içeriği:", os.listdir(libri_directory))

labels = [os.path.basename(os.path.dirname(path)) for path in audio_paths]
print("Labels length:", len(labels))

import tarfile

# dev-clean.tar dosyasının tam yolu
tar_path = '/content/drive/MyDrive/LibriSpeech/dev-clean.tar'
extract_path = '/content/drive/MyDrive/LibriSpeech/dev-clean/'

# Dosyayı açma ve çıkartma işlemi
with tarfile.open(tar_path, "r") as tar:
    tar.extractall(path=extract_path)

# Çıkartılan dizini kontrol edelim
print("dev-clean içeriği:", os.listdir(extract_path))

# LibriSpeech klasörünün içeriğini kontrol edelim
libri_clean_directory = '/content/drive/MyDrive/LibriSpeech/dev-clean/LibriSpeech/'
print("LibriSpeech içeriği:", os.listdir(libri_clean_directory))

# dev-clean alt klasörünün içeriğini kontrol edelim
dev_clean_directory = '/content/drive/MyDrive/LibriSpeech/dev-clean/LibriSpeech/dev-clean/'
print("dev-clean içeriği:", os.listdir(dev_clean_directory))

# Ses dosyalarını bulmak için glob kullanarak tüm .flac dosyalarını arayalım
import glob

# dev-clean alt dizinindeki tüm flac dosyalarını bulma
audio_paths = glob.glob('/content/drive/MyDrive/LibriSpeech/dev-clean/LibriSpeech/dev-clean/*/*/*.flac')

# Bulunan ses dosyalarını kontrol edelim
print("Bulunan ses dosyası sayısı:", len(audio_paths))
print("Örnek dosya yolları:", audio_paths[:5])

"""**Ses Dosyalarını Yükleme ve Etiketleme:**

Bu kısımda, LibriSpeech veri setindeki ses dosyalarının yolları audio_paths listesinde saklanıyor. Bu dosyalar, belirli dizinlerde yer alıyor ve her dizin, bir konuşmacıyı temsil ediyor. Kendi dosya yollarınızı ekleyerek ses dosyalarını listeleyebilirsiniz.

labels: Her ses dosyasının bulunduğu dizinin adı, yani konuşmacının kimliği etiketi olarak alınıyor. Bu, modelin öğrenmesi için etiketleri oluşturuyor.
"""

# Etiketler olarak konuşmacı kimliklerini almak
labels = [os.path.basename(os.path.dirname(os.path.dirname(path))) for path in audio_paths]

# Etiketlerin ilk birkaçını kontrol edelim
print("Etiketler:", labels[:5])

"""**Ses Dosyalarını Çıkartma ve Konuşmacı Kimliklerini Alma:**

Bir ses dosyasını yüklerken, dosyanın özelliklerini (örnekleme frekansı, uzunluğu) yazdırıyoruz ve ayrıca ses dosyasına ait MFCC (Mel-frequency cepstral coefficients) özelliklerini çıkarıyoruz. Bu özellikler, ses tanıma ve analiz için yaygın olarak kullanılır.
"""

import librosa

# İlk ses dosyasını yükleyelim
y, sr = librosa.load(audio_paths[0])

# Sesin özelliklerine bakalım
print("Yüklenen sesin örnekleme frekansı:", sr)
print("Ses uzunluğu (saniye cinsinden):", librosa.get_duration(y=y, sr=sr))

"""**MFCC (Mel-Frequency Cepstral Coefficients) çıkarma**"""

# MFCC özelliklerini çıkartalım
mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

# MFCC'nin şekline bakalım
print("MFCC şekli:", mfcc.shape)

"""** Özelliklerin Hesaplanması ve Ortalama Alma:**

Burada, her ses dosyasından çıkarılan MFCC özelliklerinin ortalamasını alıyoruz. Bu, her ses dosyasını sabit uzunlukta bir vektöre dönüştürerek, ses dosyasının uzunluğuna bağımlılığını ortadan kaldırıyor.


"""

import librosa
import numpy as np

# Özellikleri ve etiketleri depolamak için listeler
features = []
labels = []

# Ses dosyalarını işlemeye başlıyoruz
for path in audio_paths:
    # Ses dosyasını yükle
    y, sr = librosa.load(path)

    # MFCC özelliklerini çıkartalım (13 temel MFCC)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

    # Özelliklerin ortalamasını alarak tek bir vektör elde edelim (bu adım ses uzunluğundan bağımsızlaştırır)
    mfcc_mean = np.mean(mfcc, axis=1)

    # Özellikleri ve etiketleri ekleyelim
    features.append(mfcc_mean)

    # Etiketi (konuşmacı kimliği) çıkaralım
    label = os.path.basename(os.path.dirname(os.path.dirname(path)))
    labels.append(label)

# Özellikleri ve etiketleri numpy dizilerine dönüştür
X = np.array(features)
y = np.array(labels)

# Özelliklerin ve etiketlerin boyutlarına bakalım
print("Özellikler boyutu:", X.shape)
print("Etiketler boyutu:", y.shape)

"""**Veri Setinin Eğitim ve Test Setlerine Ayrılması:**

Veri setini eğitim ve test setlerine ayırıyoruz. Burada, %20'lik bir test seti oranı kullanılıyor. Bu adım, modelin eğitildiği veri ile test edildiği veri arasındaki farkı görmek için önemlidir.
"""

from sklearn.model_selection import train_test_split

# Eğitim ve test setlerine ayırma (test seti %20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Eğitim ve test setlerinin boyutlarına bakalım
print("Eğitim seti boyutu:", X_train.shape)
print("Test seti boyutu:", X_test.shape)

"""**Modelin Eğitim ve Doğrulama:**

RandomForestClassifier modeli kullanılarak eğitim verisi ile model eğitiliyor. Ardından, test seti ile tahminler yapılıyor ve modelin doğruluğu hesaplanıyor. Bu kısımda modelin doğruluğu accuracy_score fonksiyonu ile kontrol ediliyor.
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# RandomForest modelini oluştur
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Modeli eğitim verisiyle eğitelim
model.fit(X_train, y_train)

# Test seti üzerinde tahmin yapalım
y_pred = model.predict(X_test)

# Modelin doğruluğunu kontrol edelim
accuracy = accuracy_score(y_test, y_pred)
print("Model doğruluğu:", accuracy)

"""**Sınıflandırma Sonuçlarının Değerlendirilmesi:**

Modelin performansını daha detaylı incelemek için classification_report fonksiyonu kullanılıyor. Bu fonksiyon, her sınıf için precision, recall, f1-score gibi metrikleri hesaplar.
"""

from sklearn.metrics import classification_report

# Detaylı değerlendirme raporu
print(classification_report(y_test, y_pred))

"""**Farklı Performans Metriklerinin Hesaplanması:**

Son olarak, precision_score, recall_score, f1_score ve accuracy_score metrikleri hesaplanarak modelin performansı daha ayrıntılı bir şekilde değerlendirilmiş.Bu metrikler:

Precision: Doğru pozitif tahminlerin, tüm pozitif tahminlere oranı.
Recall: Doğru pozitif tahminlerin, gerçek pozitif örneklere oranı.
F1-Score: Precision ve recall'un harmonik ortalaması.
Accuracy: Tüm doğru tahminlerin toplam veri setine oranı.
Sonuçları yazdırarak modelin genel performansını gözlemliyoruz.
"""

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

# Gerçek etiketler ve modelin tahmin ettiği etiketler
y_true = [1, 0, 1, 0, 1]  # Örnek gerçek etiketler
y_pred = [1, 0, 0, 0, 1]  # Modelin tahmin ettiği etiketler

# Performans metriklerini hesapla
precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
f1 = f1_score(y_true, y_pred, average='weighted')
accuracy = accuracy_score(y_true, y_pred)

print(f'Precision: {precision:.2f}')
print(f'Recall: {recall:.2f}')
print(f'F1-Score: {f1:.2f}')
print(f'Accuracy: {accuracy:.2f}')

"""Bu sonuçlar, modelin tahminlerinin genel doğruluğunu ve modelin her sınıf için ne kadar hassas ve dengeli olduğunu gösteriyor.

ÖZETLE;
Bu kodlarda yapılan işlemler, sesli veriyi işleyip, modelin eğitilmesi ve performansını değerlendirmenin her aşamasını içeriyor. Önce ses dosyalarından özellikler çıkarıldı, ardından bunlar üzerinden eğitim ve test setleri oluşturularak, sınıflandırma modeli ile doğruluk hesaplaması yapıldı.
"""

import librosa
import matplotlib.pyplot as plt
import numpy as np

# Ses dosyasını yükle
example_file = "/content/drive/MyDrive/LibriSpeech/dev-clean/LibriSpeech/dev-clean/2902/9006/2902-9006-0014.flac"
y, sr = librosa.load(example_file, sr=16000)

# FFT ile frekans analizi
fft = np.fft.fft(y)
fft_magnitude = np.abs(fft)
fft_frequency = np.fft.fftfreq(len(y), 1 / sr)

# FFT Frekans Spektrumu görselleştir
plt.figure(figsize=(10, 4))
plt.plot(fft_frequency[:len(fft_frequency)//2], fft_magnitude[:len(fft_magnitude)//2])
plt.xlabel('Frequency (Hz)')
plt.ylabel('Magnitude')
plt.title('FFT Frequency Spectrum')
plt.grid()
plt.show()

# STFT ile frekans analizi
D = librosa.stft(y)  # STFT ile zaman-frekans dönüşümü
D_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

# STFT Spektrogramını görselleştir
plt.figure(figsize=(10, 4))
librosa.display.specshow(D_db, sr=sr, x_axis='time', y_axis='log')
plt.colorbar(format='%+2.0f dB')
plt.title('STFT Spectrogram')
plt.tight_layout()
plt.show()

from transformers import Wav2Vec2Processor, Wav2Vec2Model
import torch
import numpy as np
import librosa.display
import matplotlib.pyplot as plt

# Önceden yüklenen ses verisi (y ve sr daha önce tanımlanmıştı)
# y, sr = librosa.load(example_file, sr=16000)  # Bu adım daha önce yapıldı

# Wav2Vec2 için işleyici ve model yükleme
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
model = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base-960h")

# Veriyi işleyip modele besle
inputs = processor(y, sampling_rate=sr, return_tensors="pt", padding=True)

# Modeli çalıştır ve özellikleri al
with torch.no_grad():
    features = model(**inputs).last_hidden_state

print("Özellik çıkışı boyutu:", features.shape)

# Özellikleri görselleştir
plt.figure(figsize=(10, 4))
plt.imshow(features[0].numpy(), aspect='auto', origin='lower')
plt.colorbar()
plt.title("Wav2Vec2 Çıkışı (Spectral Features)")
plt.xlabel("Zaman")
plt.ylabel("Özellik Boyutu")
plt.tight_layout()
plt.show()

import librosa

# Ses dosyasını yükle
audio_path = '/content/LibriSpeech/LibriSpeech/dev-clean/2902/9006/2902-9006-0014.flac'
y, sr = librosa.load(audio_path, sr=None)  # y ses verisi, sr örnekleme oranı

# Sesin temel bilgilerini yazdır
print(f"Audio sample rate: {sr}")
print(f"Audio duration: {librosa.get_duration(y=y, sr=sr)} seconds")

# İlk 10 saniyelik bir kesiti dinleme (veya görselleştirme)
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
librosa.display.waveshow(y, sr=sr)
plt.title("Waveform of Audio File")
plt.show()

import os

example_file = "/content/LibriSpeech/LibriSpeech/dev-clean/2902/9006/2902-9006-0014.flac"

# Dosya var mı kontrol et
print("Dosya var mı?", os.path.exists(example_file))

from google.colab import drive
drive.mount('/content/drive')

import librosa
# Mel-Spektrogram hesapla
S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)

# Mel-Spektrogramı desibele dönüştür
S_dB = librosa.power_to_db(S, ref=np.max)

# Mel-Spektrogramı görselleştir
plt.figure(figsize=(10, 4))
librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', fmax=8000)
plt.colorbar(format='%+2.0f dB')
plt.title('Mel-Spectrogram (Spektral Kestirim)')
plt.tight_layout()
plt.show()

example_file = "/content/LibriSpeech/LibriSpeech/dev-clean/2902/9006/2902-9006-0014.flac"
y, sr = librosa.load(example_file, sr=16000)  # Ses dosyasını yükleyin

import numpy as np
import librosa.display
import matplotlib.pyplot as plt

# STFT hesapla
D = librosa.stft(y)  # Zaman-Frekans dönüşümü
D_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)  # Desibel birimine dönüştür

# STFT Spektrogramını görselleştir
plt.figure(figsize=(10, 4))
librosa.display.specshow(D_db, sr=sr, x_axis='time', y_axis='log')
plt.colorbar(format='%+2.0f dB')
plt.title('STFT Spectrogram (Spektral Kestirim)')
plt.tight_layout()
plt.show()

from transformers import Wav2Vec2Processor, Wav2Vec2Model
import torch

# Wav2Vec2 için işleyici ve model yükleme
processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
model = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base-960h")

# Veriyi işleyip modele besle
inputs = processor(y, sampling_rate=sr, return_tensors="pt", padding=True)

# Modeli çalıştır ve özellikleri al
with torch.no_grad():
    features = model(**inputs).last_hidden_state

print("Wav2Vec2 özellik çıkışı boyutu:", features.shape)

# Özellikleri görselleştir
plt.figure(figsize=(10, 4))
plt.imshow(features[0].numpy(), aspect='auto', origin='lower')
plt.colorbar()
plt.title("Wav2Vec2 Çıkışı (Spektral Özellikler)")
plt.xlabel("Zaman")
plt.ylabel("Özellik Boyutu")
plt.tight_layout()
plt.show()

